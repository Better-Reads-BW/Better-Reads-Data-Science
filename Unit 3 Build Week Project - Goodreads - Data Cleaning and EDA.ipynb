{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('book_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54301, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_authors</th>\n",
       "      <th>book_desc</th>\n",
       "      <th>book_edition</th>\n",
       "      <th>book_format</th>\n",
       "      <th>book_isbn</th>\n",
       "      <th>book_pages</th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "      <th>book_title</th>\n",
       "      <th>genres</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54296</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>In this fearless and half-crazy story, Howard ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78161E+12</td>\n",
       "      <td>256 pages</td>\n",
       "      <td>3.37</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>Taking the Field: A Fan's Quest to Run the Tea...</td>\n",
       "      <td>Sports|Baseball|Sports and Games|Sports|Nonfic...</td>\n",
       "      <td>https://images.gr-assets.com/books/1312074392l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54297</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>From the icons of the game to the players who ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.78006E+12</td>\n",
       "      <td>256 pages</td>\n",
       "      <td>3.97</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>The Baseball Talmud: Koufax, Greenberg, and th...</td>\n",
       "      <td>Nonfiction|Sports and Games|Sports</td>\n",
       "      <td>https://images.gr-assets.com/books/1348841629l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54298</th>\n",
       "      <td>Howard Megdal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kindle Edition</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.66</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilpon's Folly - The Story of a Man, His Fortu...</td>\n",
       "      <td>Sports|Baseball|Abandoned</td>\n",
       "      <td>https://images.gr-assets.com/books/1394277097l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54299</th>\n",
       "      <td>Mimi Baird|Eve Claxton</td>\n",
       "      <td>Soon to be a major motion picture, from Brad P...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hardcover</td>\n",
       "      <td>9.7808E+12</td>\n",
       "      <td>272 pages</td>\n",
       "      <td>3.82</td>\n",
       "      <td>867</td>\n",
       "      <td>187</td>\n",
       "      <td>He Wanted the Moon: The Madness and Medical Ge...</td>\n",
       "      <td>Nonfiction|Autobiography|Memoir|Biography|Psyc...</td>\n",
       "      <td>https://images.gr-assets.com/books/1403192135l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54300</th>\n",
       "      <td>Leah Price</td>\n",
       "      <td>The Anthology and the Rise of the Novel brings...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Paperback</td>\n",
       "      <td>9.78052E+12</td>\n",
       "      <td>236 pages</td>\n",
       "      <td>3.58</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>The Anthology and the Rise of the Novel: From ...</td>\n",
       "      <td>Criticism|Literary Criticism|Philosophy|Theory...</td>\n",
       "      <td>https://images.gr-assets.com/books/1349014225l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 book_authors  \\\n",
       "54296           Howard Megdal   \n",
       "54297           Howard Megdal   \n",
       "54298           Howard Megdal   \n",
       "54299  Mimi Baird|Eve Claxton   \n",
       "54300              Leah Price   \n",
       "\n",
       "                                               book_desc book_edition  \\\n",
       "54296  In this fearless and half-crazy story, Howard ...          NaN   \n",
       "54297  From the icons of the game to the players who ...          NaN   \n",
       "54298                                                NaN          NaN   \n",
       "54299  Soon to be a major motion picture, from Brad P...          NaN   \n",
       "54300  The Anthology and the Rise of the Novel brings...          NaN   \n",
       "\n",
       "          book_format    book_isbn book_pages  book_rating  book_rating_count  \\\n",
       "54296       Hardcover  9.78161E+12  256 pages         3.37                 27   \n",
       "54297       Hardcover  9.78006E+12  256 pages         3.97                 34   \n",
       "54298  Kindle Edition          NaN        NaN         3.66                 32   \n",
       "54299       Hardcover   9.7808E+12  272 pages         3.82                867   \n",
       "54300       Paperback  9.78052E+12  236 pages         3.58                 12   \n",
       "\n",
       "       book_review_count                                         book_title  \\\n",
       "54296                  9  Taking the Field: A Fan's Quest to Run the Tea...   \n",
       "54297                  5  The Baseball Talmud: Koufax, Greenberg, and th...   \n",
       "54298                  3  Wilpon's Folly - The Story of a Man, His Fortu...   \n",
       "54299                187  He Wanted the Moon: The Madness and Medical Ge...   \n",
       "54300                  3  The Anthology and the Rise of the Novel: From ...   \n",
       "\n",
       "                                                  genres  \\\n",
       "54296  Sports|Baseball|Sports and Games|Sports|Nonfic...   \n",
       "54297                 Nonfiction|Sports and Games|Sports   \n",
       "54298                          Sports|Baseball|Abandoned   \n",
       "54299  Nonfiction|Autobiography|Memoir|Biography|Psyc...   \n",
       "54300  Criticism|Literary Criticism|Philosophy|Theory...   \n",
       "\n",
       "                                               image_url  \n",
       "54296  https://images.gr-assets.com/books/1312074392l...  \n",
       "54297  https://images.gr-assets.com/books/1348841629l...  \n",
       "54298  https://images.gr-assets.com/books/1394277097l...  \n",
       "54299  https://images.gr-assets.com/books/1403192135l...  \n",
       "54300  https://images.gr-assets.com/books/1349014225l...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_rating</th>\n",
       "      <th>book_rating_count</th>\n",
       "      <th>book_review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54301.000000</td>\n",
       "      <td>5.430100e+04</td>\n",
       "      <td>54301.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.020027</td>\n",
       "      <td>4.350449e+04</td>\n",
       "      <td>2011.60218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.362100</td>\n",
       "      <td>2.126572e+05</td>\n",
       "      <td>7627.07287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.830000</td>\n",
       "      <td>4.070000e+02</td>\n",
       "      <td>35.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.030000</td>\n",
       "      <td>2.811000e+03</td>\n",
       "      <td>188.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.220000</td>\n",
       "      <td>1.274500e+04</td>\n",
       "      <td>822.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.588580e+06</td>\n",
       "      <td>160776.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        book_rating  book_rating_count  book_review_count\n",
       "count  54301.000000       5.430100e+04        54301.00000\n",
       "mean       4.020027       4.350449e+04         2011.60218\n",
       "std        0.362100       2.126572e+05         7627.07287\n",
       "min        0.000000       0.000000e+00            0.00000\n",
       "25%        3.830000       4.070000e+02           35.00000\n",
       "50%        4.030000       2.811000e+03          188.00000\n",
       "75%        4.220000       1.274500e+04          822.00000\n",
       "max        5.000000       5.588580e+06       160776.00000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminating duplicates and rows with no book ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['book_rating_count'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_authors             0\n",
       "book_desc             1317\n",
       "book_edition         48779\n",
       "book_format           1649\n",
       "book_isbn            12829\n",
       "book_pages            2495\n",
       "book_rating              0\n",
       "book_rating_count        0\n",
       "book_review_count        0\n",
       "book_title               0\n",
       "genres                3170\n",
       "image_url              663\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54226, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48412, 12)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset =\"book_title\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46712, 12)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset =\"book_desc\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_authors             0\n",
       "book_desc                1\n",
       "book_edition         42204\n",
       "book_format           1222\n",
       "book_isbn            10339\n",
       "book_pages            1891\n",
       "book_rating              0\n",
       "book_rating_count        0\n",
       "book_review_count        0\n",
       "book_title               0\n",
       "genres                2625\n",
       "image_url              377\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use book description as sole feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46712, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['book_authors','book_desc','book_title']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46711, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem.porter import *\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate observations with non-English words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_english(text):\n",
    "    english = ' '.join([w for w in text.split() if wordnet.synsets(w)])\n",
    "    return english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: make_english(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_words'] = df['book_desc'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['num_words'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_authors    0\n",
       "book_desc       0\n",
       "book_title      0\n",
       "num_words       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44548, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['book_authors','book_desc','book_title']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminate punctuation, numbers and capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    new_text = re.sub('<.*?>', '', text)   # remove HTML tags\n",
    "    new_text = re.sub(\"[!@#$+%*:()'-]\",'',new_text) # remove punc.\n",
    "    new_text = re.sub(r'\\d+','',new_text)# remove numbers\n",
    "    new_text = new_text.lower() # lower case, .upper() for upper\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize and remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: tokenizer.tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use lemmatizer and join result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['book_desc'] = df['book_desc'].apply(lambda x: word_stemmer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_authors    0\n",
       "book_desc       0\n",
       "book_title      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize and use cosine similarity to get top 5 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44530, 3)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[[18536,18538,22495,22865,26160,26219,28878,37109,37573]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44521, 3)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('preprocessed_df.csv', index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unprocessed = pd.read_csv('book_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unprocessed = df_unprocessed[df_unprocessed['book_rating_count'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unprocessed = df_unprocessed.drop_duplicates(subset =\"book_title\")\n",
    "df_unprocessed = df_unprocessed.drop_duplicates(subset =\"book_desc\")\n",
    "df_unprocessed = df_unprocessed[['book_authors','book_desc','book_title']]\n",
    "df_unprocessed = df_unprocessed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unprocessed['book_desc_eng'] = df_unprocessed['book_desc'].apply(lambda x: make_english(x))\n",
    "df_unprocessed['num_words'] = df_unprocessed['book_desc_eng'].apply(lambda x: len(x.split()))\n",
    "df_unprocessed = df_unprocessed[df_unprocessed['num_words'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unprocessed = df_unprocessed[['book_authors','book_desc','book_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44548, 3)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = np.array(df['book_desc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create preprocessor function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = PorterStemmer()\n",
    "    new_text = re.sub('<.*?>', '', text)   # remove HTML tags\n",
    "    new_text = re.sub(\"[!@#$+%*:()'-]\",'',new_text) # remove punc.\n",
    "    new_text = re.sub(r'\\d+','',new_text)# remove numbers\n",
    "    new_text = new_text.lower() # lower case, .upper() for upper\n",
    "    tokenized_text = tokenizer.tokenize(new_text)\n",
    "    words = [w for w in tokenized_text if w not in stopwords.words('english')]\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in words]\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in lem_text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'could surviv wild everyon make sure dont live see morn ruin place known north america lie nation panem shine capitol surround twelv outli district capitol harsh cruel keep district line forc send one boy one girl age twelv eighteen particip annual hunger game fight death live tv sixteenyearold katniss everdeen life alon mother younger sister regard death sentenc forc repres district game katniss close dead surviv second natur without realli mean becom contend win start make choic weigh surviv human life love new york time bestsel author suzann collin deliv equal part suspens philosophi adventur romanc sear novel set futur unsettl parallel present'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor('Could you survive on your own, in the wild, with everyone out to make sure you dont live to see the morning? In the ruins of a place once known as North America lies the nation of Panem, a shining Capitol surrounded by twelve outlying districts. The Capitol is harsh and cruel and keeps the districts in line by forcing them all to send one boy and one girl between the ages of twelve and eighteen to participate in the annual Hunger Games, a fight to the death on live TV. Sixteen-year-old Katniss Everdeen, who lives alone with her mother and younger sister, regards it as a death sentence when she is forced to represent her district in the Games. But Katniss has been close to dead before - and survival, for her, is second nature. Without really meaning to, she becomes a contender. But if she is to win, she will have to start making choices that weigh survival against humanity and life against love. New York Times bestselling author Suzanne Collins delivers equal parts suspense and philosophy, adventure and romance, in this searing novel set in a future with unsettling parallels to our present.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(text):\n",
    "    documents = [preprocessor(text)]\n",
    "    tfidf_matrix_new = tfidf_vectorizer.transform(documents)\n",
    "    array = cosine_similarity(tfidf_matrix_new, tfidf_matrix)[0]\n",
    "    recommender = df.copy()\n",
    "    recommender['cs'] = array\n",
    "    recommender.sort_values(by=['cs'], ascending=False)\n",
    "    return recommender.nlargest(5, 'cs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predictions('I want to read a book about scientific discoveries and space exploration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"21738\":{\"book_authors\":\"Mary Roach\",\"book_desc\":\"bestsel author stiff bonk explor irresist strang univers space travel life space world devoid thing need live hot fresh space explor way explor mean much person give much weird happen walk smell happen vomit helmet space possibl human bodi surviv mile answer space agenc set manner quizzic startlingli bizarr space mari roach possibl preview space ever leav space shuttl train toilet crash test new space capsul fill roach take u entertain trip scienc life space space\",\"book_title\":\"Packing for Mars: The Curious Science of Life in the Void\",\"cs\":0.41357821},\"2028\":{\"book_authors\":\"Carl Sagan|Ann Druyan\",\"book_desc\":\"pulitz author trace explor space suggest surviv may depend wise use stir book reveal scientif discoveri alter percept challeng u weigh mani\",\"book_title\":\"Pale Blue Dot: A Vision of the Human Future in Space\",\"cs\":0.4100823107},\"38964\":{\"book_authors\":\"Piers Bizony\",\"book_desc\":\"boldli go book gone explor come realiti person space travel want astronaut grew\",\"book_title\":\"How To Build Your Own Spaceship: The Science Of Mass Space Travel\",\"cs\":0.313127331},\"53172\":{\"book_authors\":\"David Hitt|Owen  Garriott|Joe Kerwin\",\"book_desc\":\"unit state soviet union went explor space live space station conceiv logic successor apollo moon concept execut vast space say noth monument technolog homestead two astronaut nasa tell dramat stori first space station begin fieri homestead space much stori technolog scientif also sometim often inspir account hardwork individu shepherd program heroic exhaust studi comet well ultim descent indian featur unpublish diari astronaut book replet person recollect experi skylab crew work bring safe\",\"book_title\":\"Homesteading Space: The Skylab Story\",\"cs\":0.2940924208},\"34648\":{\"book_authors\":\"Jon Butterworth\",\"book_desc\":\"discoveri boson made headlin around two peter theori predict share nobel discoveri culmin largest experi ever atla cm experi larg hadron realli boson discoveri chang understand fundament law feel like part one lead physicist book first popular insid account hunt stori incred scientif inspir technolog innov also stori happen expens experi blow neutrino may may travel faster realiti life underground bunker book also leav work knowledg new physic discoveri particl mean defin law take cut edg modern scientif\",\"book_title\":\"Smashing Physics\",\"cs\":0.2832986021}}'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.to_json(orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://bettereads.herokuapp.com/api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "data = json.dumps({'book_desc': 'I want to read a book about startups and entrepreneurs who started small but achieved great success'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"book_desc\": \"I want to read a book about startups and entrepreneurs who started small but achieved great success\"}\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "send = requests.post(url, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'4644': {'book_authors': 'Alejandro Cremades', 'book_desc': 'art startup fundrais take fresh look rais money focu chang face startup new regul make old advic le startup money increasingli move new water founder need access book help navig onlin world startup fundrais explan expert perspect new digit world find tip trick rais money invest startup earli stage growth develop clear strategi base new realiti surround startup financ world massiv state chang occur increas pace intens startup paradigm process must chang book show startup fund expert coach new rule job act impact fundrais insight startup earli stage growth money need get ventur pitch optim right common reli tale superstar stori uniqu appli except game play old rule get left found startup look art startup fundrais provid uptotheminut guidanc art startup art startup fundrais must read even consid start fundrais book give get speak wisdom draper founder draper draper art startup fundrais mandatori read entrepreneur look rais book enabl help mani earli stage compani answer tough question former chief oper offic appl chairman atlanti capit often daunt least understood aspect start new busi peopl experienc act art startup fundrais unlock key secret fundrais newli mint chairman vice chairman dun new york time author wire book provid concis tour fundrais entrepreneuri expertis full terrif job make complic process simpl gener partner flybridg capit partner senior lectur harvard busi need amaz sell art startup fundrais provid essenti master core skill serial entrepreneur prolif angel mani entrepreneur find right investor ventur daunt experi equiti give uniqu perspect fundrais art startup fundrais insight entrepreneur look close round financ chang professor stern school perfect approach rais invest certain tribal knowledg u learn sever fail art startup fundrais captur everi bit advic give entrepreneur look paul partner cofound art startup fundrais must read clear outlin startup commun step success golden era good idea proof concept get access know founder ceo famili offic matter great busi rais master contributor cofound pluto tv cofound art startup fundrais translat art share proven case studi provid need servic futur josh manag partner citi light read requir entrepreneur build busi rais well written inform written man testament dedic creativ confront challeng entrepreneur rais carter serial entrepreneur princip cross atlant capit bleed edg equiti talk startup andrew manag director capit provid stepbystep guidebook entrepreneur rather spend time think chang world instead think rais manag partner join capit superb book guidanc arm entrepreneur necessari tool close success meaning round execut director robin hood art startup fundrais practic comprehens resourc entrepreneur use captur startup need success rapidli evolv financ also provid tip fundament build busi chang execut director angel capit money founder world make exponenti easier educ process rais equiti capit dive handson advic book provid solid foundat selfeduc deliv approach format key lesson takeaway everi art startup essenti read entrepreneur allen manag director endeavor', 'book_title': 'The Art of Startup Fundraising', 'cs': 0.3785328327}, '18858': {'book_authors': 'Brad Feld|Amy Batchelor', 'book_desc': 'real life insight take make entrepreneur entrepreneur alway look lead intens time alway short relationship stress extend period critic partner intend stay startup brad entrepreneur person experi wife offer rich insight success lead balanc life want play hard work want fulfil life twenti year experi field address startup peopl put asid workahol way reward life exampl entrepreneuri coupl success relationship work practic advic adapt chang inevit up down associ brad field investor success entrepreneur twenti relationship success way make navig territori startup life wellround insight advic need succeed busi', 'book_title': 'Startup Life: Surviving and Thriving in a Relationship with an Entrepreneur', 'cs': 0.3483933378}, '12639': {'book_authors': 'Eric Ries', 'book_desc': 'startup mani failur lean startup new approach adopt across chang way compani built new product defin startup organ dedic creat new condit extrem true one person garag group season profession fortun common mission penetr fog uncertainti discov success path sustain lean startup approach foster compani capit effici leverag human creativ inspir lesson lean reli rapid scientif well number practic shorten product develop measur actual progress resort vaniti learn custom realli enabl compani shift direct alter plan inch minut wast time creat elabor busi lean startup offer entrepreneur compani size way test vision adapt adjust provid scientif approach creat manag success startup age compani need innov', 'book_title': \"The Lean Startup: How Today's Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses\", 'cs': 0.293221945}, '20656': {'book_authors': 'Brad Feld', 'book_desc': 'essenti guid build support entrepreneuri pop citi like boulder boston even countri type entrepreneuri ecosystem drive innov small busi document longterm dynam build commun entrepreneur feed twenti year entrepreneur capitalist brad experi well contribut innov startup reliabl resourc skill explor take creat entrepreneuri commun along offer valuabl insight increas breadth depth entrepreneuri ecosystem multipli connect entrepreneur improv access entrepreneuri much four critic principl need form sustain startup entrepreneur ventur capitalist seek fresh idea new brad field investor success entrepreneur twenti practic guid show startup commun also show make work anywher', 'book_title': 'Startup Communities: Building an Entrepreneurial Ecosystem in Your City', 'cs': 0.282561183}, '148': {'book_authors': 'Dr. Seuss', 'book_desc': 'hate whole christma pleas ask one quit know rank right scroog come scowl holiday grump live cave side loom who noisi holiday prepar infern sing happi littl citizen annoy decid frivol merriment must idea santa strap heavi antler quiver dog construct makeshift head strip cheer who yuletid glee quit place disturb makeshift santa slither chimney empti bag steal even log humbl take ramshackl sleigh dump wait hear sob who wake discov trap christma imagin dismay discov child simultan ador fear twist testimoni undaunt cheer transcend natur growth potenti heart two size holiday classic perfect read aloud favorit littl', 'book_title': 'How the Grinch Stole Christmas!', 'cs': 0.1846673742}}\n"
     ]
    }
   ],
   "source": [
    "print(send.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = '\\nltk_data\\corpora\\stopwords\\english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    words = [w for w in text if w not in stopwords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unprocessed['book_desc'] = df_unprocessed['book_desc'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44548, 3)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nchib\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
